Our experimental evaluation compared four deep learning architectures—LSTM, RNN (GRU), CNN, and VAE—for time series classification on the ECG200 dataset. We conducted a systematic hyperparameter grid search with 16 total configurations (4 per model), training each for 50 epochs. The results reveal clear performance differences: RNN (GRU) achieved the highest mean accuracy of 81% with a best configuration reaching 84%, followed by CNN at 79.75%, LSTM at 75.25%, and VAE at 71.5%. The GRU architecture demonstrated superior classification quality with the highest F1-macro score of 0.788, though it exhibited the largest standard deviation (�4.24%), indicating sensitivity to hyperparameter choices. In contrast, CNN showed the most consistent performance across configurations (�2.63% std dev) while LSTM was even more stable (�1.26%) but at a lower baseline accuracy.

The top-performing configurations were dominated by GRU variants, with three of the top five spots. Notably, both a deeper network (64 hidden units, 2 layers) and a wider network (128 hidden units, 1 layer) achieved identical 84% accuracy, though the single-layer variant trained 30% faster (5.08s vs 7.24s). The best CNN configuration used 64 filters with 2 blocks, achieving 82% accuracy in 10.48s—adding a third block improved F1 marginally but tripled training time to 36s. This pattern revealed a critical insight: deeper architectures don't always improve performance and often come with substantial computational costs. For LSTM, the optimal configuration was 64 hidden units with 2 layers (77% accuracy), while VAE performed best with 64 hidden units and 16-dimensional latent space but still only reached 76% accuracy, confirming its unsuitability for discriminative tasks despite being designed for generative modeling.

Computational efficiency analysis revealed significant trade-offs. VAE was the fastest to train (mean 1.74s) and infer (0.012s) with the smallest model size (20K parameters), but its poor accuracy makes it impractical for this task. LSTM offered a good balance with moderate training time (3.34s), fast inference (0.026s), and compact size (54K parameters), making it suitable for resource-constrained deployments where sub-80% accuracy is acceptable. RNN achieved the best accuracy-speed trade-off, training twice as fast as CNN while delivering 2% higher accuracy, though its inference time (0.049s) was slower than LSTM. CNN had the highest computational cost with mean training time of 15.67s (�13.99s variance) and slowest inference (0.259s), taking up to 36s for the deepest configurations—a significant drawback unless specific convolutional inductive biases are required.

Hyperparameter sensitivity varied considerably across models. LSTM proved most robust with only a 3% accuracy range across all configurations, making it predictable but limiting its ceiling. GRU showed the highest sensitivity with a 9% accuracy swing (75-84%), indicating that careful tuning is critical but rewarding when done correctly. The hidden size was particularly important for GRU: 128 units outperformed 64 units by 9% in single-layer networks, though adding layers to 64-unit networks closed this gap. CNN showed moderate sensitivity with a clear preference for 64 over 32 filters (+4-5% accuracy), but block depth had minimal impact. VAE exhibited high variance (9% range) with strong dependence on model capacity, requiring both larger hidden size and higher latent dimensions for reasonable performance.

Based on these findings, we recommend RNN (GRU) with 128 hidden units and 1 layer for maximum accuracy (84%) and efficient training, especially for offline batch classification. For applications requiring stable performance with minimal tuning, CNN with 64 filters and 2 blocks provides 82% accuracy with low variance. LSTM with 64 hidden units and 2 layers is best suited for real-time inference scenarios on resource-constrained devices despite its lower accuracy (77%). VAE should not be used for this classification task. Future work should explore ensemble methods combining GRU and CNN predictions, hybrid architectures, and validation on the FordA dataset to confirm generalizability. The key insight from this study is that GRU's simpler gating mechanism outperforms LSTM's more complex design for this ECG classification task, and that model depth provides diminishing returns compared to careful selection of width and architecture type.
